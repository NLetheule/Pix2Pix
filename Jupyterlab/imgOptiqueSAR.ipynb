{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtention des path de la BDD d'image SAR et Optique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "\n",
    "#import data_loader \n",
    "\n",
    "# path_bdd = \"/work/OT/ai4geo/DATA/DATA_MULTIMODAL/\"\n",
    "path_bdd_France = \"/work/OT/ai4geo/DATA/DATA_MULTIMODAL/France/\"\n",
    "path_bdd_USA = \"/work/OT/ai4geo/DATA/DATA_MULTIMODAL/USA/\"\n",
    "\n",
    "\n",
    "def get_file_in_folder(folder):\n",
    "    \"\"\"\n",
    "        Liste récursivement le contenu des sous-répertoires\n",
    "    \"\"\"\n",
    "    list_file = []\n",
    "    for f in os.listdir(folder):\n",
    "        if os.path.isdir(folder+'/'+f): # si f est un dossier\n",
    "            list_file.append(get_file_in_folder(folder+'/'+f))\n",
    "        else :\n",
    "            list_file.append(folder+'/'+f) \n",
    "    \n",
    "    return(list_file)\n",
    "\n",
    "# list_file = get_file_in_folder(path_bdd)\n",
    "list_file_France = get_file_in_folder(path_bdd_France)\n",
    "list_file_USA = get_file_in_folder(path_bdd_USA)\n",
    "\n",
    "def select_file_name(list_file, word):\n",
    "    list_selected = []\n",
    "    for file in list_file:\n",
    "        if type(file) is list:\n",
    "            list_selected.append(select_file_name(file, word))\n",
    "        elif str(file).find(word) != -1:\n",
    "                list_selected.append(file)\n",
    "    return list_selected\n",
    "\n",
    "# list_SAR_file = select_file_name(list_file, 'S1moy')\n",
    "# list_optique_file1 = select_file_name(list_file, 'S2')\n",
    "# list_optique_file2 = select_file_name(list_file, 'S2mosa')\n",
    "# list_optique_file = list_optique_file1 + list_optique_file2\n",
    "# list_raster_file = select_file_name(list_file, 'OSM')\n",
    "# list_SRTM_file = select_file_name(list_file, 'SRTM')\n",
    "# list_S1_file = select_file_name(list_file, 'S1_')\n",
    "list_SAR_file_France = select_file_name(list_file_France, 'S1moy')\n",
    "list_SAR_file_USA = select_file_name(list_file_USA, 'S1moy')\n",
    "list_optique_file_France = select_file_name(list_file_France, 'S2')\n",
    "list_optique_file_USA = select_file_name(list_file_USA, 'S2mosa')\n",
    "\n",
    "# for i in len list_\n",
    "list_SAR_file_France[12].remove([])\n",
    "list_optique_file_France[12].remove([])\n",
    "list_SAR_file_France[21].remove([])\n",
    "list_optique_file_France[21].remove([])\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Création de la BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "/work/OT/ai4geo/DATA/DATA_MULTIMODAL/France//Zone11/Couple11_S1moy_2016-08-29__dual_02_02.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "#Define the data splits.\n",
    "nb_train_data = 0.6\n",
    "nb_val_data = 0.2\n",
    "nb_test_data = 0.2\n",
    "\n",
    "percent = 0.02\n",
    "\n",
    "img_folder = [[] for i in range(3)]\n",
    "SAR_folder = [[] for i in range(3)]\n",
    "for i in range(len(list_SAR_file_France)):\n",
    "    nb_imgs_zone = min(len(list_SAR_file_France[i]), len(list_optique_file_France[i]))\n",
    "    sorted_SAR_list = sorted(list_SAR_file_France[i])\n",
    "    sorted_optique_list = sorted(list_optique_file_France[i])\n",
    "    for k in range(int(nb_imgs_zone*0.6*percent)):\n",
    "        img_folder[0].append(sorted_SAR_list[k])  \n",
    "        SAR_folder[0].append(sorted_optique_list[k]) \n",
    "    for k in range(int(nb_imgs_zone*0.6*percent),int(nb_imgs_zone*0.8*percent)):    \n",
    "        img_folder[1].append(sorted_SAR_list[k])  \n",
    "        SAR_folder[1].append(sorted_optique_list[k]) \n",
    "    for k in range(int(nb_imgs_zone*0.8*percent),int(nb_imgs_zone*percent)):\n",
    "        img_folder[2].append(sorted_SAR_list[k])  \n",
    "        SAR_folder[2].append(sorted_optique_list[k]) \n",
    "\n",
    "print(len(img_folder[0]))\n",
    "print(len(SAR_folder[0]))   \n",
    "print(img_folder[0][0])\n",
    "\n",
    "class ImgOptiqueSAR(Dataset):\n",
    "    def __init__(self, img_folder, SAR_folder, patch_size=256):\n",
    "        self.imgs = []\n",
    "        self.SARs = []\n",
    "\n",
    "        #This will convert the numpy array to a tensor\n",
    "        conversion = T.ToTensor()\n",
    "        overlap = patch_size \n",
    "\n",
    "        for img_index in range(0,len(img_folder)):\n",
    "            print(\"Working on image \" + str(img_index))\n",
    "            #Load the tile and the corresponding SAR truth.\n",
    "            img = io.imread(img_folder[img_index])/2048\n",
    "            SAR_open = gdal.Open(SAR_folder[img_index])\n",
    "            SAR_band = SAR_open.GetRasterBand(1)\n",
    "            SAR = SAR_band.ReadAsArray()\n",
    "\n",
    "            for i in np.arange(patch_size//2, img.shape[0] - patch_size // 2 + 1, overlap):\n",
    "                for j in np.arange(patch_size//2, img.shape[1] - patch_size // 2 + 1, overlap):\n",
    "                      #Crop the image and the ground truth into patch around (i,j) and save\n",
    "                      #them in self.imgs and self.SARs arrays.\n",
    "                      #For the image, note that we are taking the three channels (using \":\")\n",
    "                      #for the 3rd dimension, and we do the conversion to tensor.\n",
    "                      self.imgs.append(conversion(img[i - patch_size//2:i + patch_size // 2, j - patch_size // 2:j + patch_size // 2,:]))\n",
    "                      self.SARs.append(SAR[i - patch_size//2:i + patch_size // 2, j - patch_size // 2:j + patch_size // 2])\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = self.imgs[idx].float()\n",
    "        SAR = self.SARs[idx].float()\n",
    "\n",
    "        return img, torch.from_numpy(SAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Chargement de la BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on image 0\n",
      "Working on image 1\n",
      "Working on image 2\n",
      "Working on image 3\n",
      "Working on image 4\n",
      "Working on image 5\n",
      "Working on image 6\n",
      "Working on image 7\n",
      "Working on image 8\n",
      "Working on image 9\n",
      "Working on image 10\n",
      "Working on image 11\n",
      "Working on image 12\n",
      "Working on image 13\n",
      "Working on image 0\n",
      "Working on image 1\n",
      "Working on image 2\n",
      "Working on image 3\n",
      "Working on image 4\n",
      "Working on image 5\n",
      "torch.Size([2, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2 #The batch size should generally be as big as your machine can take it.\n",
    "\n",
    "training_dataset = ImgOptiqueSAR(img_folder[0], SAR_folder[0])\n",
    "validate_dataset = ImgOptiqueSAR(img_folder[1], SAR_folder[1])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=batch_size, shuffle=True)\n",
    "validate_loader = torch.utils.data.DataLoader(dataset=validate_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(train_loader.dataset.imgs[5].shape) # probleme --> taille d'une image 2*256*256 et pas 3*256*256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Architecture Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Architecture PatchGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Unet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-357e81970c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmake_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Unet' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
